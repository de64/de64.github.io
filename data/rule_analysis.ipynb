{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "source": [
    "# Deriving Grammatical Gender Rule for German Nouns\n",
    "\n",
    "This notebook serves as a basis of one of the services implemented in the open - source software for learning of German for English speakers. In this notebook, a set of rules are derived which allow with accuracy of 82% to determine the grammatical gender of German noun. Such rule applies to roughly 80% (6000+) of frequently used nouns in German. The repository is [here](https://gitlab.com/iaros/learn-german), and you can give the software in repository a try by navigating to [bit.do/d3l](bit.do/d3l); Here d3l stands for \"Data Driven Deutsch Lernen\".\n",
    "\n",
    "## The why\n",
    "\n",
    "So why care about grammatical gender of a German noun? Consider the following two phrases in German and their translation:\n",
    "\n",
    "`Ich gebe den Vogel der Katze.` = \"I give the bird to the cat\"\n",
    "\n",
    "`Ich gebe dem Vogel die Katze.` = \"To the bird I give the cat \"\n",
    "\n",
    "See, the direction of action (who is given to who) is determined by articles (`den, der, dem, die`) in the sentences above; by switching the articles only, the direction is reversed. Imagine what kind of derps and misunderstandings an incorrect use of articles can lead to! \"I gave the lady to the documents\", \"I received my landlord from keys\", ...\n",
    "\n",
    "To form a correct article before a noun (e.g. `den` before `Vogel` or `der` before `Katze`), you need to know a correct case of a noun, as well as the gender of the noun. For some information on how to determine a case of noun, see [here](https://www.quora.com/What-is-the-simplest-explanation-for-the-difference-between-nominative-accusative-dative-and-genitive-articles) or [here](http://www.lsa.umich.edu/german/hmr/grammatik/basic_chart.html). \n",
    "\n",
    "As for the second ingredient - gender of noun, it is even more complex; every noun in German language has a grammatical gender, one of `maskulin`, `feminin` and `neuter`. So should one learn genders for 30k+ German nouns!? No, not really. This would be a rather daunting task, so people tried to come up with some classification rules, which help to determine the gender of a noun. For example, a set of such rules is described in a [great article by fluent in 3 month](https://www.fluentin3months.com/german-noun-genders/). A classification of a noun is done by it's ending, with rules given below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "baseline_rule = {\n",
    "    'f': ['e', 'ie', 'heit', 'ei', 'in', 'ik', 'keit', 'schaft', 'ung', 'tät', 'ur', 'tion'],\n",
    "    'm': ['er', 'el', 'ling', 'ich', 'ig', 'ner', 'ismus', 'or', 'us', 'eich', 'ant'],\n",
    "    'n': ['chen', 'o', 'lein', 'en', 'il', 'ma', 'tel', 'ment', 'nis', 'tum', 'um']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "99d103900219b409a0b981ae4a1ffccdd8b41721"
   },
   "source": [
    "Here f stands for `feminin`, m stands for `maskulin`, and n stands for `neuter`.  Learning such rule is expected to take less effort than going through gender of many thousands of German nouns. But how well does such rule works? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "dbfa174343f7a1e8f6c6bd058c08c9bdbfa38731"
   },
   "source": [
    "## Evaluation of the baseline rule\n",
    "\n",
    "In order to evaluate the rule, a [database dump of en.wiktionary.org](https://dumps.wikimedia.org/enwiktionary/latest/) was parsed for German nouns. Script that does just that is located in [the \"data\" folder of this repository](https://gitlab.com/iaros/learn-german). Only the end result is attached to this notebook; Two versions are used - one with all the extracted nouns, and another with all the nouns that are also present in 150k phrases scraped from various subtitles to German shows. Loading procedures for the datasets are given below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "8cdd909602d6ba8779ee845b6bf4f1a315deb68e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total nouns: 7619\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Schatz', 'm'),\n",
       " ('Tür', 'f'),\n",
       " ('Bekommen', 'n'),\n",
       " ('Gestern', 'n'),\n",
       " ('Kerl', 'm')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# read the noun list\n",
    "nouns = json.load(open('de_frequent_nouns.json', 'r'))\n",
    "\n",
    "# simplify the list to the list of tuples\n",
    "nouns = [(v['noun'], v['gender']) for v in nouns]\n",
    "\n",
    "# weed out the p gender (apparently a plural)\n",
    "nouns = [n for n in nouns if n[1] in {'f', 'm', 'n'}]\n",
    "\n",
    "# example data\n",
    "print('Total nouns:', len(nouns))\n",
    "nouns[100:105]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0cb718fbd2929f82338b2a2bb08a34f6f166b035"
   },
   "source": [
    "We will need evaluation procedure in later parts of this notebook, so lets write it down as reusable functions below. See comments in the code below for explanations; Note that this code is a bit more complex than what you would expect as it is reused later in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "eb8931e3be320397fb08273323e0e710416a1336"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def rule_applies(rule, word):\n",
    "    \"\"\"Checks whether a rule given as a dict with keys f, m, n containing \n",
    "    values as arrays of ending applies to the word.\"\"\"\n",
    "    \n",
    "    for endings in rule.values():\n",
    "        for ending in endings:\n",
    "            if word.endswith(ending):\n",
    "                return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "def rule_predict(rule, word):\n",
    "    # estimates ending for a given word\n",
    "    result = 'f'  # default: feminine gender\n",
    "    fitting_ending_length = 0  # longer ending takes precedence over shorter one\n",
    "    \n",
    "    for gender, endings in rule.items():\n",
    "        for ending in endings:\n",
    "            if word.endswith(ending) and len(ending) > fitting_ending_length:\n",
    "                result = gender\n",
    "                fitting_ending_length = len(ending)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def rule_confusion(rule):\n",
    "    \"\"\"Finds all endings that could be confused in the rule\"\"\"\n",
    "    endings = [(e, g) for g in rule for e in rule[g]]\n",
    "    \n",
    "    all_confusion = []\n",
    "    for end, gen in endings:\n",
    "        confusion = []  # which endings can be confused?\n",
    "        for end2, gen2 in endings:\n",
    "            if end2.endswith(end) and len(end2) > len(end) and gen2 != gen:\n",
    "                confusion.append(end2 + \"(\" + gen2 + \")\")\n",
    "        \n",
    "        if confusion:\n",
    "            all_confusion.append(end + \"(\" + gen + \") can be confused with \" + ', '.join(confusion))\n",
    "    \n",
    "    return all_confusion\n",
    "\n",
    "def rule_quality(rule, all_nouns, per_ending_accuracy=False, rule_analysis=False):\n",
    "    \"\"\"For a rule given as a dict with keys f, m, n containing \n",
    "    values as arrays of ending, evaluate this rule on a set of \n",
    "    nouns given as a list of tuples (noun str, gender \\in m,f,n)\n",
    "    \n",
    "    Returns a dict with various rule performance metrics, such as:\n",
    "    - Coverage: fraction of all supplied nouns, for which the rule\n",
    "        applies;\n",
    "    - Accuracy: overall accuracy of the rule on nouns where the\n",
    "        rule applies. \n",
    "    \"\"\"\n",
    "    \n",
    "    # result will be a dict with various metrics\n",
    "    result = {}\n",
    "    \n",
    "    # first, select all the nouns that rule can be applied to\n",
    "    nouns = [n for n in all_nouns if rule_applies(rule, n[0])]\n",
    "    \n",
    "    # percentage of all nouns covered by the rule\n",
    "    result['Coverage %'] = round(len(nouns) / len(all_nouns), 3)\n",
    "    result['Coverage count'] = len(nouns)\n",
    "    result['Total count'] = len(all_nouns)\n",
    "    \n",
    "    # make estimations with rule\n",
    "    y = np.array([gender for word, gender in nouns])  # ground truth\n",
    "    y_pred = np.array([rule_predict(rule, word) for word, _ in nouns])  # estimations with rule\n",
    "    # accuracy of the rule\n",
    "    result['Accuracy'] = round(np.mean(y == y_pred), 3)\n",
    "    \n",
    "    # get the accuracy per class\n",
    "    per_class_stats = {}\n",
    "    for clas in set(y):\n",
    "        I = y == clas\n",
    "        per_class_stats[clas] = {\n",
    "            'accuracy': round(np.mean(y[I] == y_pred[I]), 3),\n",
    "            'instances': np.sum(I)\n",
    "        }\n",
    "    result['Gender accuracy'] = per_class_stats\n",
    "    \n",
    "    # get accuracy per ending of noun\n",
    "    per_ending_stats = {}\n",
    "    for gender, endings in rule.items():\n",
    "        for ending in endings:\n",
    "            I = np.array([word.endswith(ending) for word, gender in nouns])\n",
    "            per_ending_stats[ending] = {\n",
    "                'accuracy': round(np.mean(y[I] == y_pred[I]), 3),\n",
    "                'gender': gender,\n",
    "                'instances': np.sum(I)\n",
    "            }\n",
    "    \n",
    "    result['Ending count'] = len(per_ending_stats)\n",
    "    \n",
    "    if per_ending_accuracy:\n",
    "        result['Ending accuracy'] = per_ending_stats\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8405782c58941537c635b5fc12b30b0c2dcb84cc"
   },
   "source": [
    "Alright, now lets apply the functions to the data and the baseline rule!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "f114b40e8b335071bdbb8fb8f69ccc2180096fef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Accuracy': 0.828,\n",
      " 'Coverage %': 0.633,\n",
      " 'Coverage count': 4821,\n",
      " 'Ending accuracy': {'ant': {'accuracy': 0.944, 'gender': 'm', 'instances': 18},\n",
      "                     'chen': {'accuracy': 0.951, 'gender': 'n', 'instances': 162},\n",
      "                     'e': {'accuracy': 0.874, 'gender': 'f', 'instances': 1364},\n",
      "                     'ei': {'accuracy': 0.771, 'gender': 'f', 'instances': 48},\n",
      "                     'eich': {'accuracy': 0.667, 'gender': 'm', 'instances': 12},\n",
      "                     'el': {'accuracy': 0.619, 'gender': 'm', 'instances': 265},\n",
      "                     'en': {'accuracy': 0.807, 'gender': 'n', 'instances': 797},\n",
      "                     'er': {'accuracy': 0.787, 'gender': 'm', 'instances': 830},\n",
      "                     'heit': {'accuracy': 1.0, 'gender': 'f', 'instances': 70},\n",
      "                     'ich': {'accuracy': 0.762, 'gender': 'm', 'instances': 21},\n",
      "                     'ie': {'accuracy': 0.946, 'gender': 'f', 'instances': 111},\n",
      "                     'ig': {'accuracy': 1.0, 'gender': 'm', 'instances': 10},\n",
      "                     'ik': {'accuracy': 0.844, 'gender': 'f', 'instances': 32},\n",
      "                     'il': {'accuracy': 0.622, 'gender': 'n', 'instances': 37},\n",
      "                     'in': {'accuracy': 0.62, 'gender': 'f', 'instances': 171},\n",
      "                     'ismus': {'accuracy': 1.0, 'gender': 'm', 'instances': 21},\n",
      "                     'keit': {'accuracy': 1.0, 'gender': 'f', 'instances': 93},\n",
      "                     'lein': {'accuracy': 1.0, 'gender': 'n', 'instances': 6},\n",
      "                     'ling': {'accuracy': 0.95, 'gender': 'm', 'instances': 20},\n",
      "                     'ma': {'accuracy': 0.733, 'gender': 'n', 'instances': 15},\n",
      "                     'ment': {'accuracy': 0.929, 'gender': 'n', 'instances': 28},\n",
      "                     'ner': {'accuracy': 0.95, 'gender': 'm', 'instances': 60},\n",
      "                     'nis': {'accuracy': 0.71, 'gender': 'n', 'instances': 31},\n",
      "                     'o': {'accuracy': 0.648, 'gender': 'n', 'instances': 54},\n",
      "                     'or': {'accuracy': 0.872, 'gender': 'm', 'instances': 39},\n",
      "                     'schaft': {'accuracy': 1.0, 'gender': 'f', 'instances': 39},\n",
      "                     'tel': {'accuracy': 0.515, 'gender': 'n', 'instances': 33},\n",
      "                     'tion': {'accuracy': 1.0, 'gender': 'f', 'instances': 103},\n",
      "                     'tum': {'accuracy': 0.7, 'gender': 'n', 'instances': 10},\n",
      "                     'tät': {'accuracy': 1.0, 'gender': 'f', 'instances': 28},\n",
      "                     'um': {'accuracy': 0.638, 'gender': 'n', 'instances': 69},\n",
      "                     'ung': {'accuracy': 0.986, 'gender': 'f', 'instances': 506},\n",
      "                     'ur': {'accuracy': 0.654, 'gender': 'f', 'instances': 52},\n",
      "                     'us': {'accuracy': 0.568, 'gender': 'm', 'instances': 81}},\n",
      " 'Ending count': 34,\n",
      " 'Gender accuracy': {'f': {'accuracy': 0.947, 'instances': 2347},\n",
      "                     'm': {'accuracy': 0.7, 'instances': 1345},\n",
      "                     'n': {'accuracy': 0.733, 'instances': 1129}},\n",
      " 'Total count': 7619}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "result = rule_quality(baseline_rule, nouns, True)\n",
    "pprint(result, width=120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "38437139491eb7dae5df790983dfcafe7aeb3e12"
   },
   "source": [
    "## Discussion of baseline rule\n",
    "\n",
    "First of all, the rule applies to roughly 4800 nouns out of 7600. On the **63% of of all German nouns where rule applies**, the accuracy is 83%. Thus for the next noun that you recognize as one fitting to the rule, you have **83% chance to recognize correct the gender**. There are also **34 endings to learn** to use the rule.\n",
    "\n",
    "It is evident also that for some genders the rule is more accurate; In particular the feminine gender, the most numerous one, is also the one where the rule achieves maximal 95% accuracy. The rule gives 70% accuracy on other genders. Thus you can be more **confident with feminine nouns**.\n",
    "\n",
    "Also depending on an ending of a noun, accuracy can vary quite largely; Almost all 500 nouns ending with `ung` are feminine, yet 60 percent of 250 of nouns ending with `el` are masculine.  So if you intend to learn those, **learn first endings with high accuracy**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "deedcca7c07464308c2cccff8130fdc04e2c2fb5"
   },
   "source": [
    "## Is there a better rule?\n",
    "\n",
    "A better rule could be the one which with the same number of endings to memorize and recognition accuracy, would cover more nouns. Alternatively, for same nouns coverage and rule number, it would be more accurate. Of course, one can also try to optimize the number of rules. \n",
    "\n",
    "With an assumption that there could be a rule which is in some sense better, lets outline a strategy for how to search for a rule. Firstly, all possible endings can be extracted from the list of nouns (our dataset); then, for every ending one can count how indicative the ending is of some specific gender.  Imagine that we took some hypothetical `ending1` and `ending2`, and counted instances of feminine, masculine and neuter nouns that end with an ending:\n",
    "\n",
    "`ending1: {'f': 20, 'm': 10, 'n':70}`\n",
    "\n",
    "`ending2: {'f': 23, 'm': 1, 'n':1}`\n",
    "\n",
    "Clearly, `ending2` is more indicative of specific gender `f`.  The `ending1` is less accurate, but it covers more nouns. One way to construct new rule is to compose it of endings, which strike a ballance between how indicative they are of particular gender, and how many nouns they cover. For example, we could look for all endings that cover at least 50 nouns, and separate the most likely gender with at least 80% accuracy. Then one can use all such endings as a rule. A function which implements such approach is given below. See comments there for more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "9924719d6c49298acc5056d3ee6d39ba70b304da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f': ['e', 'it', 'ng', 'aft', 'ion', 'rin'],\n",
      " 'm': ['ner', 'ag', 'f', 'all', 'tz', 'ger', 'ler', 'her'],\n",
      " 'n': ['en']}\n"
     ]
    }
   ],
   "source": [
    "def derive_rule(nouns, min_accuracy=0.8, min_nouns=50):\n",
    "    # this will contain bins for every ending\n",
    "    ending_bins = {}\n",
    "\n",
    "    # make counts for all endings\n",
    "    for word, gender in nouns:\n",
    "        word = word.lower()  # ending might include first letter of word\n",
    "        for ending_len in [1, 2, 3, 4, 5, 6]:\n",
    "            ending = word[-ending_len:]\n",
    "            if ending not in ending_bins:\n",
    "                ending_bins[ending] = {'f':0, 'm':0, 'n':0}\n",
    "            ending_bins[ending][gender] += 1\n",
    "    \n",
    "    # calculate statistics for every ending\n",
    "    endings = []\n",
    "    for ending, count in ending_bins.items(): \n",
    "        endings.append({\n",
    "            \"ending\": ending,\n",
    "            \"nouns\": sum(count.values()),\n",
    "            \"accuracy\": max(count.values()) / sum(count.values()),\n",
    "            \"gender\": max(count.keys(), key=count.get)\n",
    "        })\n",
    "    \n",
    "    # filter out the endings\n",
    "    endings = [\n",
    "        e for e in endings if e['nouns'] >= min_nouns and e['accuracy'] >= min_accuracy\n",
    "    ]\n",
    "    \n",
    "    # make a rule out of this\n",
    "    rule = {\n",
    "        gender: [stats['ending'] for stats in endings if stats['gender'] == gender]\n",
    "        for gender in ['f', 'm', 'n']\n",
    "    }\n",
    "    \n",
    "    # remove endings within one gender that contain other ending\n",
    "    for gender, endings in rule.items():\n",
    "        rule[gender] = [\n",
    "            e for e in endings \n",
    "            if not any([  # look for any ending which is shorter and current one's ending\n",
    "                True for e2 in endings if len(e2) < len(e) and e.endswith(e2)\n",
    "            ])\n",
    "        ]\n",
    "    \n",
    "    return rule\n",
    "\n",
    "pprint(derive_rule(nouns, min_accuracy=0.8, min_nouns=50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bcc9fb876c2b6ed034e70fc9cccaf1e5da8ff35f"
   },
   "source": [
    "Let's evaluate how well such rule performs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "02322645290471825844f011a30659b0ede12b83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Accuracy': 0.872,\n",
      " 'Coverage %': 0.492,\n",
      " 'Coverage count': 3750,\n",
      " 'Ending count': 15,\n",
      " 'Gender accuracy': {'f': {'accuracy': 0.995, 'instances': 2135},\n",
      "                     'm': {'accuracy': 0.581, 'instances': 866},\n",
      "                     'n': {'accuracy': 0.858, 'instances': 749}},\n",
      " 'Total count': 7619}\n"
     ]
    }
   ],
   "source": [
    "rule = derive_rule(nouns, min_accuracy=0.8, min_nouns=50)\n",
    "result = rule_quality(rule, nouns, per_ending_accuracy=False)\n",
    "pprint(result, width=120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "491dad86f2721d82eba54a64096a8c731995fb38"
   },
   "source": [
    "With such approach we derived a rule directly from the data with 15 endings, which has a bit higher accuracy of 87%, and reduced coverage of 49%. Notice that **less than half of rules** compared to baseline rule is used. This indicates that there might be a possibility to improve on baseline. Lets try and do that. To do so, two parameters need to be adjusted - `min_accuracy` and `min_nouns`. Lets do this in the sections below!\n",
    "\n",
    "Note that the optimization of such paramters is done by hand, but potentially one could even use some optimization algorithm, such as Bayesian Optimization. For simplicity, a function below is used for optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "77c2b0b56b595d306a6ef8348e977ab58cf908ec"
   },
   "outputs": [],
   "source": [
    "def experiment(min_accuracy=0.8, min_nouns=50):\n",
    "    # derive the rule itself\n",
    "    rule = derive_rule(nouns, min_accuracy, min_nouns)\n",
    "    \n",
    "    print('Quality or rule:')\n",
    "    pprint(rule_quality(rule, nouns, per_ending_accuracy=False), width=120)\n",
    "    \n",
    "    # print the rule\n",
    "    print('Derived rule:')\n",
    "    pprint(rule, compact=True)\n",
    "    \n",
    "    print('Any confusing endings:')\n",
    "    pprint(rule_confusion(rule))\n",
    "    \n",
    "    print('Ending per gender:')\n",
    "    pprint({g: len(v) for g, v in rule.items()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0b516dda2f65b00b249b25228e65bde0f5a3371c"
   },
   "source": [
    "## Result 1. Rule with smallest possible number of endings, with stats of baseline\n",
    "\n",
    "It is good to see results of your learning soon, so initial small rule might be of interest. The rule that matches baseline with minimal number of endings is given below.\n",
    "\n",
    "Note that derived rule uses **half of rules of baseline**, that is, only **17 endings need to be memorized**. The rule has equivalent accuracy and coverage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "31d744be892b8698ca8a0d8f8d9dcd62ebd8494c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quality or rule:\n",
      "{'Accuracy': 0.832,\n",
      " 'Coverage %': 0.629,\n",
      " 'Coverage count': 4796,\n",
      " 'Ending count': 17,\n",
      " 'Gender accuracy': {'f': {'accuracy': 0.943, 'instances': 2322},\n",
      "                     'm': {'accuracy': 0.746, 'instances': 1470},\n",
      "                     'n': {'accuracy': 0.701, 'instances': 1004}},\n",
      " 'Total count': 7619}\n",
      "Derived rule:\n",
      "{'f': ['e', 'it', 'ng', 'nz', 'on', 'ft', 'rin'],\n",
      " 'm': ['nn', 'r', 'll', 'ag', 'f', 'tz', 'ang'],\n",
      " 'n': ['en', 'aus', 'rn']}\n",
      "Any confusing endings:\n",
      "['ng(f) can be confused with ang(m)']\n",
      "Ending per gender:\n",
      "{'f': 7, 'm': 7, 'n': 3}\n"
     ]
    }
   ],
   "source": [
    "experiment(0.71, 37)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "772f8bf4badc1e807b14b78b5d62d8ba667d1133"
   },
   "source": [
    "## Result 2. Highest possible coverage with baseline accuracy and number of endings\n",
    "\n",
    "Lets see if we can improve on baseline rule coverage. More nouns covered directly translates into less learning of German; Therefore optimization of coverage leads to direct savings of learning time.\n",
    "\n",
    "The resulting rule is given below. The rule has **same number of endings and accuracy**, yet it achieves **9.2% higher coverage, or 708 more nouns**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "c059c33672e5d6a17a874f92f7d032cf2190b0f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quality or rule:\n",
      "{'Accuracy': 0.82,\n",
      " 'Coverage %': 0.726,\n",
      " 'Coverage count': 5534,\n",
      " 'Ending count': 34,\n",
      " 'Gender accuracy': {'f': {'accuracy': 0.929, 'instances': 2456},\n",
      "                     'm': {'accuracy': 0.788, 'instances': 1913},\n",
      "                     'n': {'accuracy': 0.645, 'instances': 1165}},\n",
      " 'Total count': 7619}\n",
      "Derived rule:\n",
      "{'f': ['e', 'g', 'it', 'ei', 'ät', 'nz', 'on', 'ik', 'ft', 'rin'],\n",
      " 'm': ['nn', 'r', 'ss', 'll', 'nd', 'ag', 'f', 'tz', 'ing', 'ug', 'sch', 'kel',\n",
      "       'b', 'rm', 'an', 'gel', 'ang', 'ist', 'kt'],\n",
      " 'n': ['en', 'aus', 'ment', 'rn', 'nis']}\n",
      "Any confusing endings:\n",
      "['g(f) can be confused with ag(m), ing(m), ug(m), ang(m)']\n",
      "Ending per gender:\n",
      "{'f': 10, 'm': 19, 'n': 5}\n"
     ]
    }
   ],
   "source": [
    "experiment(0.66, 27)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "efed0f35b6b96f84d3c1f2333b98941036815f18"
   },
   "source": [
    "## Result 3. Near maximal coverage with minimal number of endings\n",
    "\n",
    "Here is a simple idea: if two of the genders can be estimated accurately, if another word comes and its ending is unknown, it is probably of the remaining third gender. This offers an opportunity for reduced amount of information to be learned.\n",
    "\n",
    "Below is a rule just like that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "acfa6b4c7ecafba04ca9a4a1a64699203e500021"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total work: 4745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:    9.8s\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed:   17.4s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:   27.1s\n",
      "[Parallel(n_jobs=-1)]: Done 632 tasks      | elapsed:   39.8s\n",
      "[Parallel(n_jobs=-1)]: Done 866 tasks      | elapsed:   55.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1136 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1442 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1784 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 2162 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 2576 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done 3026 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 3512 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 4034 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=-1)]: Done 4592 tasks      | elapsed:  5.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quality or rule:\n",
      "{'Accuracy': 0.799,\n",
      " 'Coverage %': 0.806,\n",
      " 'Coverage count': 6142,\n",
      " 'Ending count': 38,\n",
      " 'Gender accuracy': {'f': {'accuracy': 0.915, 'instances': 2529},\n",
      "                     'm': {'accuracy': 0.773, 'instances': 2210},\n",
      "                     'n': {'accuracy': 0.631, 'instances': 1403}},\n",
      " 'Total count': 7619}\n",
      "Derived rule:\n",
      "{'f': ['e', 'g', 'it', 'ei', 'ät', 'nz', 'on', 'ik', 'ft', 'ur', 'rin'],\n",
      " 'm': ['ch', 'nn', 'r', 'st', 'ss', 'll', 'nd', 'ag', 'f', 'tz', 'ing', 'ug',\n",
      "       'el', 'b', 'rm', 'an', 'ang', 'kt'],\n",
      " 'n': ['en', 'aus', 'ld', 'o', 'ent', 'rn', 'nis', 'il', 'um']}\n",
      "Any confusing endings:\n",
      "['g(f) can be confused with ag(m), ing(m), ug(m), ang(m)',\n",
      " 'r(m) can be confused with ur(f)']\n",
      "Ending per gender:\n",
      "{'f': 11, 'm': 18, 'n': 9}\n",
      "Best result: (0.5916666666666668, 30) with objective -0.799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 4745 out of 4745 | elapsed:  5.1min finished\n"
     ]
    }
   ],
   "source": [
    "from skopt import Optimizer\n",
    "from skopt.space import Real, Integer\n",
    "\n",
    "\n",
    "class myobj():\n",
    "    def __init__(self, config):\n",
    "        \"\"\"\n",
    "        Contains:\n",
    "        {\n",
    "            \"objective\": {\n",
    "                \"name\": name prop\n",
    "                \"weight\": weight of objective\n",
    "            }\n",
    "            \"constraints\": [\n",
    "            {'name': name of constraint, 'target': value should be less than metric}\n",
    "            ]\n",
    "        }\n",
    "        \"\"\"\n",
    "        self.config = config\n",
    "    \n",
    "    \n",
    "    def __call__(self, min_accuracy, min_nouns):\n",
    "        rule = derive_rule(nouns, min_accuracy, min_nouns)\n",
    "        rq = rule_quality(rule, nouns, per_ending_accuracy=False)\n",
    "        rc = rule_confusion(rule)\n",
    "        rq['Exceptions'] = len(rc)\n",
    "        \n",
    "        # Indicates complexity if most complex endings are not learned\n",
    "        rq['complexity'] = sum(len(r) for g, r in rule.items()) - max(len(r) for g, r in rule.items())\n",
    "        \n",
    "        \n",
    "        \n",
    "        config = self.config\n",
    "        obj = config['objective']\n",
    "        metric = rq[obj['name']] * obj['weight']\n",
    "        \n",
    "        for constraint in config['constraints']:\n",
    "            value = rq[constraint['name']]\n",
    "            if 'leq' in constraint:\n",
    "                violation = max(0, value - constraint['leq']) * constraint['weight']\n",
    "            else:\n",
    "                violation = max(0, constraint['geq'] - value) * constraint['weight']\n",
    "            metric += violation\n",
    "\n",
    "        return metric\n",
    "        \n",
    "obj = myobj({\n",
    "    'objective': {'name': 'Ending count', 'weight': 1.0 / 37},\n",
    "    'constraints': [\n",
    "        {'name': 'Accuracy', 'geq': 0.828, 'weight': 10.0},\n",
    "        {'name': 'Coverage %', 'geq': 0.633, 'weight': 10.0},\n",
    "    ]\n",
    "})\n",
    "\n",
    "        \n",
    "obj = myobj({\n",
    "    'objective': {'name': 'Accuracy', 'weight': -1.0},\n",
    "    'constraints': [\n",
    "        {'name': 'Coverage %', 'geq': 0.8, 'weight': 4.0},\n",
    "        {'name': 'Ending count', 'leq': 45, 'weight': 10.0},\n",
    "    ]\n",
    "})\n",
    "\n",
    "from random import randint, uniform\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "P = [(amin, nmin) for amin in np.linspace(0.3, 0.9, 73) for nmin in range(5, 70)]\n",
    "print(\"Total work:\", len(P))\n",
    "F = Parallel(n_jobs=-1, verbose=5)(delayed(obj)(*p) for p in P)\n",
    "i = np.argmin(F)\n",
    "experiment(*P[i])\n",
    "print('Best result:', P[i], 'with objective', F[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "799d73c41860291b73f5801fdb89c275b4eaef01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quality or rule:\n",
      "{'Accuracy': 0.8,\n",
      " 'Coverage %': 0.974,\n",
      " 'Coverage count': 7424,\n",
      " 'Ending count': 107,\n",
      " 'Gender accuracy': {'f': {'accuracy': 0.902, 'instances': 2752},\n",
      "                     'm': {'accuracy': 0.776, 'instances': 2787},\n",
      "                     'n': {'accuracy': 0.684, 'instances': 1885}},\n",
      " 'Total count': 7619}\n",
      "Derived rule:\n",
      "{'f': ['e', 'in', 'hr', 'au', 'g', 'ht', 'it', 'i', 'ät', 'nz', 'on', 'tat',\n",
      "       'ik', 'art', 'ft', 'uer', 'ur', 'hrt', 'bahn', 'ra', 'ex'],\n",
      " 'm': ['h', 's', 'nn', 'r', 'ein', 'st', 'l', 'den', 'eg', 'nd', 'ag', 'ck',\n",
      "       'nt', 'ott', 'f', 'ame', 'z', 'ort', 'ing', 'nk', 'ug', 'hn', 'wagen',\n",
      "       'ig', 'alt', 'at', 'arzt', 'rd', 'b', 'm', 'an', 'mut', 'p', 'ang',\n",
      "       'sten', 'kt', 'itt', 'ton', 'rg', 'pen', 'bau'],\n",
      " 'n': ['es', 'n', 'aus', 'al', 'os', 'ld', 'o', 'echt', 'id', 'land', 'immer',\n",
      "       'ind', 'ück', 'ent', 'tt', 'och', 'hiff', 'wort', 'ende', 'sser', 'erz',\n",
      "       'ert', 'iel', 'tel', 'oss', 'nis', 'lz', 'ma', 'ot', 'isch', 'buch',\n",
      "       'il', 'eck', 'um', 'eh', 'ed', 'as', 'zeug', 'tier', 'ach', 'ad', 'rk',\n",
      "       'ell', 'et', 'om']}\n",
      "Any confusing endings:\n",
      "['e(f) can be confused with ame(m), ende(n)',\n",
      " 'in(f) can be confused with ein(m)',\n",
      " 'au(f) can be confused with bau(m)',\n",
      " 'g(f) can be confused with eg(m), ag(m), ing(m), ug(m), ig(m), ang(m), rg(m), '\n",
      " 'zeug(n)',\n",
      " 'ht(f) can be confused with echt(n)',\n",
      " 'on(f) can be confused with ton(m)',\n",
      " 'h(m) can be confused with och(n), isch(n), buch(n), eh(n), ach(n)',\n",
      " 's(m) can be confused with es(n), aus(n), os(n), oss(n), nis(n), as(n)',\n",
      " 'r(m) can be confused with hr(f), uer(f), ur(f), immer(n), sser(n), tier(n)',\n",
      " 'l(m) can be confused with al(n), iel(n), tel(n), il(n), ell(n)',\n",
      " 'nd(m) can be confused with land(n), ind(n)',\n",
      " 'ck(m) can be confused with ück(n), eck(n)',\n",
      " 'nt(m) can be confused with ent(n)',\n",
      " 'f(m) can be confused with hiff(n)',\n",
      " 'z(m) can be confused with nz(f), erz(n), lz(n)',\n",
      " 'ort(m) can be confused with wort(n)',\n",
      " 'ug(m) can be confused with zeug(n)',\n",
      " 'hn(m) can be confused with bahn(f)',\n",
      " 'at(m) can be confused with tat(f)',\n",
      " 'm(m) can be confused with um(n), om(n)',\n",
      " 'n(n) can be confused with in(f), on(f), bahn(f), nn(m), ein(m), den(m), '\n",
      " 'hn(m), wagen(m), an(m), sten(m), ton(m), pen(m)',\n",
      " 'tt(n) can be confused with ott(m), itt(m)']\n",
      "Ending per gender:\n",
      "{'f': 21, 'm': 41, 'n': 45}\n"
     ]
    }
   ],
   "source": [
    "# (0.7029066640547783, 42) = 83, 63, 16\n",
    "# (0.5137855775715072, 9) = 0.80, 97, 107 (62)\n",
    "experiment(0.5137855775715072, 9)  # 80, 80, 37???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fec321f11b2299d6604b001813cd604cd3d45c9b"
   },
   "source": [
    "## Summary\n",
    "\n",
    "A number of rules for German noun gender estimation were derived from the noun data, scraped from wiktionary.org. All of the rules operate on the endings of the nouns; A baseline rule from a popular online resource for language learning is introduced. It is shown that all the derived rules improve in some way over the baseline rule. The rules will also be available [here](http://bit.do/d3l) for anyone wanting to learn them and practice estimating the noun gender."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
